{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =64\n",
    "train_dataset = datasets.FashionMNIST(root='./FashionMNIST/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./FashionMNIST/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset.train_data.shape)\n",
    "print(train_loader.dataset.train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "classes = ('T-shirt/top', 'Trouser','Pullover','Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top Trouser Pullover Trouser\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4],nrow=4))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(torch.nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(Inception,self).__init__()\n",
    "        \n",
    "        self.branch1x1 = nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        \n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16,24,kernel_size=5,padding=2)\n",
    "        \n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16,24,kernel_size=3,padding=1)\n",
    "        self.branch3x3_3 = nn.Conv2d(24,24,kernel_size=3,padding=1)\n",
    "        \n",
    "        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x,kernel_size=3,padding=1,stride =1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        \n",
    "        output =[ branch1x1,branch5x5,branch3x3,branch_pool]\n",
    "        \n",
    "        return torch.cat(output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(88,20,kernel_size=5)\n",
    "        \n",
    "        self.incept1 = Inception(in_channels=10)\n",
    "        self.incept2 = Inception(in_channels=20)\n",
    "        \n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(1408, 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = self.incept1(x)\n",
    "        \n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = self.incept2(x)\n",
    "        \n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.301847\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.286026\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.218995\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.697130\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.814392\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.704826\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.716702\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.630160\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.717141\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.564631\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.834481\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.669474\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.614401\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.594722\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.591836\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.491253\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.534951\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.772181\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.633500\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.396705\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.464301\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.475300\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.488223\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.647550\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.629097\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.434002\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.748904\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.526934\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.511571\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.221078\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.222602\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.409839\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.486144\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.528460\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.302903\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.458696\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.485551\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.298264\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.571840\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.419450\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.458063\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.372980\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.342504\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.406088\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.599294\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.308650\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.390098\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.385489\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.344769\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.453635\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.437552\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.480540\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.317012\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.290550\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.326502\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.255692\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.349412\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.538838\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.342611\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.369716\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.264939\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.272319\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.347253\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.477413\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.379967\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.402996\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.329242\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.346942\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.413198\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.497059\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.569327\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.288023\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.213429\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.404458\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.218809\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.369773\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.444371\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.351011\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.358270\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.197722\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.325249\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.444537\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.303403\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.563305\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.365717\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.428233\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.278396\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.299699\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.349227\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.277625\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.538485\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.290310\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.201544\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.314099\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.392795\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.285889\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.344883\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.317052\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.169834\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.594136\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i ,(data,target) in enumerate(train_loader):\n",
    "        data,target = Variable(data),Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(data)\n",
    "        loss = criterion(y_pred,target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0057, Accuracy: 8711/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    output = model.forward(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(output, target).item()\n",
    "    # get the index of the max\n",
    "    pred = output.data.max(dim=1,keepdim=True)[1]\n",
    "    \n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
